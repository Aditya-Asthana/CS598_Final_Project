{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations (Report)\n",
    "Authors: Aditya Asthana, Krish Desai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./cs598env/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in ./cs598env/lib/python3.8/site-packages (0.17.2)\n",
      "Requirement already satisfied: pandas in ./cs598env/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: matplotlib in ./cs598env/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: torchxrayvision in ./cs598env/lib/python3.8/site-packages (1.3.4)\n",
      "Requirement already satisfied: jinja2 in ./cs598env/lib/python3.8/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: filelock in ./cs598env/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: sympy in ./cs598env/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./cs598env/lib/python3.8/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: fsspec in ./cs598env/lib/python3.8/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: networkx in ./cs598env/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: numpy in ./cs598env/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./cs598env/lib/python3.8/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./cs598env/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./cs598env/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./cs598env/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./cs598env/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./cs598env/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./cs598env/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./cs598env/lib/python3.8/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in ./cs598env/lib/python3.8/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./cs598env/lib/python3.8/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./cs598env/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: scikit-image>=0.16 in ./cs598env/lib/python3.8/site-packages (from torchxrayvision) (0.21.0)\n",
      "Requirement already satisfied: requests>=1 in ./cs598env/lib/python3.8/site-packages (from torchxrayvision) (2.32.3)\n",
      "Requirement already satisfied: imageio in ./cs598env/lib/python3.8/site-packages (from torchxrayvision) (2.35.1)\n",
      "Requirement already satisfied: tqdm>=4 in ./cs598env/lib/python3.8/site-packages (from torchxrayvision) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./cs598env/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./cs598env/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./cs598env/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in ./cs598env/lib/python3.8/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: scipy>=1.8 in ./cs598env/lib/python3.8/site-packages (from scikit-image>=0.16->torchxrayvision) (1.10.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in ./cs598env/lib/python3.8/site-packages (from scikit-image>=0.16->torchxrayvision) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in ./cs598env/lib/python3.8/site-packages (from scikit-image>=0.16->torchxrayvision) (0.4)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./cs598env/lib/python3.8/site-packages (from scikit-image>=0.16->torchxrayvision) (2023.7.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./cs598env/lib/python3.8/site-packages (from requests>=1->torchxrayvision) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./cs598env/lib/python3.8/site-packages (from requests>=1->torchxrayvision) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./cs598env/lib/python3.8/site-packages (from requests>=1->torchxrayvision) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./cs598env/lib/python3.8/site-packages (from requests>=1->torchxrayvision) (3.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/adityaasthana/uiuc-mcs/CS598_Final_Report/cs598env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision pandas matplotlib torchxrayvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Pseudo-Labeling with TorchXRayVision\n",
    "We’ll load a pretrained DenseNet121 (CheXpert-trained), run inference on each image, and threshold the “Pneumonia” score at 0.5 to create binary labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityaasthana/uiuc-mcs/CS598_Final_Report/cs598env/lib/python3.8/site-packages/torchxrayvision/utils.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# **Cell 2: Imports & Globals**\n",
    "# --------------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import torchxrayvision as xrv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths\n",
    "IMAGE_DIR = Path(\"data_sources_small\")            # your raw scans\n",
    "MANIFEST_DIR = Path(\"outputs_small\")           # where CSVs will go\n",
    "MANIFEST_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Revised Cell 3: Load Pretrained Model & Preprocessor (CPU, 1-channel)**\n",
    "import torchxrayvision as xrv\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load TorchXRayVision DenseNet-121 (grayscale input)\n",
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-chex\")\n",
    "model = model.eval()  # keep on CPU; no .cuda()\n",
    "\n",
    "# Preprocessing: resize → center-crop → grayscale → to-tensor → normalize\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Grayscale(num_output_channels=1),     # ensure 1 channel :contentReference[oaicite:0]{index=0}\n",
    "    transforms.ToTensor(),                           # yields shape [1,224,224]\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229]), # single-channel norms :contentReference[oaicite:1]{index=1}\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Input image does not appear to be normalized correctly. The input image has the range [-2.12,2.20] which doesn't seem to be in the [-1024,1024] range. This warning may be wrong though. Only the first image is tested and we are only using a heuristic in an attempt to save a user from using the wrong normalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_sources_small/00000001_000.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_sources_small/00000001_001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_sources_small/00000001_002.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_sources_small/00000002_000.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_sources_small/00000003_000.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_path  label\n",
       "0  data_sources_small/00000001_000.png      1\n",
       "1  data_sources_small/00000001_001.png      1\n",
       "2  data_sources_small/00000001_002.png      1\n",
       "3  data_sources_small/00000002_000.png      1\n",
       "4  data_sources_small/00000003_000.png      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **Revised Cell 4: Generate Pseudo-Labels (1-channel inputs)**\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "records = []\n",
    "for fname in sorted(os.listdir(IMAGE_DIR)):\n",
    "    path = IMAGE_DIR / fname\n",
    "    img = Image.open(path).convert(\"L\")                # open as grayscale :contentReference[oaicite:2]{index=2}\n",
    "    tensor = preprocess(img).unsqueeze(0)              # shape [1,1,224,224]\n",
    "    with torch.no_grad():\n",
    "        scores = model(tensor).numpy().squeeze()       # outputs [21] pathology logits\n",
    "    idx = model.pathologies.index(\"Pneumonia\")\n",
    "    prob = torch.sigmoid(torch.tensor(scores[idx])).item()\n",
    "    label = int(prob >= 0.5)\n",
    "    records.append({\"image_path\": str(path), \"label\": label})\n",
    "\n",
    "df_labels = pd.DataFrame(records)\n",
    "df_labels.to_csv(MANIFEST_DIR/\"pseudo_labels.csv\", index=False)\n",
    "df_labels.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create Two Domains\n",
    "- **Domain A:** your original images  \n",
    "- **Domain B:** apply a consistent augmentation (brightness & blur) to simulate a second “dataset”  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./cs598env/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in ./cs598env/lib/python3.8/site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./cs598env/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./cs598env/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./cs598env/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/adityaasthana/uiuc-mcs/CS598_Final_Report/cs598env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# **Cell 5: Define Augmentation & Build Manifests**\n",
    "# --------------------------------------------------------------\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
    "    transforms.GaussianBlur(5),\n",
    "])\n",
    "\n",
    "# prepare lists\n",
    "manifests = {\"A\": [], \"B\": []}\n",
    "\n",
    "for _, row in df_labels.iterrows():\n",
    "    path, lbl = row[\"image_path\"], row[\"label\"]\n",
    "    # Domain A record\n",
    "    manifests[\"A\"].append({\"image_path\": path, \"label\": lbl, \"domain\": 0})\n",
    "    # Domain B: save augmented copy to a temp folder\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    aug = aug_transform(img)\n",
    "    save_path = IMAGE_DIR/\"domainB\"/os.path.basename(path)\n",
    "    save_path.parent.mkdir(exist_ok=True)\n",
    "    aug.save(save_path)\n",
    "    manifests[\"B\"].append({\"image_path\": str(save_path), \"label\": lbl, \"domain\": 1})\n",
    "\n",
    "!pip install scikit-learn\n",
    "# Split each into train/val/test (80/10/10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "for dom, recs in manifests.items():\n",
    "    df = pd.DataFrame(recs)\n",
    "    train, temp = train_test_split(df, stratify=df.label, test_size=0.2, random_state=0)\n",
    "    val, test = train_test_split(temp, stratify=temp.label, test_size=0.5, random_state=0)\n",
    "    train.to_csv(MANIFEST_DIR/f\"{dom}_train.csv\", index=False)\n",
    "    val.to_csv(MANIFEST_DIR/f\"{dom}_val.csv\", index=False)\n",
    "    test.to_csv(MANIFEST_DIR/f\"{dom}_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Dataset & DataLoader\n",
    "Define a PyTorch `Dataset` that reads our CSVs and returns `(img, label, domain)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Cell 6: Dataset Class**\n",
    "# --------------------------------------------------------------\n",
    "class ChestDataset(Dataset):\n",
    "    def __init__(self, manifest_csv, transform=None):\n",
    "        self.df = pd.read_csv(manifest_csv)\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "        ])\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row.image_path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        return img, row.label, row.domain\n",
    "\n",
    "def make_loader(dom, split, bs=32, shuffle=True):\n",
    "    path = MANIFEST_DIR/f\"{dom}_{split}.csv\"\n",
    "    return DataLoader(ChestDataset(path), batch_size=bs, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model & ERM Training\n",
    "We’ll sample equally from each domain per step (“infinite loader” logic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Cell 7 (CPU only): Model Factory & Training Loop**\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def make_model():\n",
    "    m = models.densenet121(pretrained=False)\n",
    "    m.classifier = nn.Linear(m.classifier.in_features, 1)\n",
    "    return m  # CPU model\n",
    "\n",
    "def train_erm(domains, max_steps=5000, lr=1e-4):\n",
    "    loaders = {d: make_loader(d, \"train\") for d in domains}\n",
    "    iters = {d: iter(loaders[d]) for d in domains}\n",
    "    model = make_model()            # CPU\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        for d in domains:\n",
    "            try:\n",
    "                imgs, labs, _ = next(iters[d])\n",
    "            except StopIteration:\n",
    "                iters[d] = iter(loaders[d])\n",
    "                imgs, labs, _ = next(iters[d])\n",
    "            # no .cuda()\n",
    "            preds = model(imgs).squeeze()\n",
    "            loss = crit(preds, labs.float())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        if (step+1) % 1000 == 0:\n",
    "            print(f\"Step {step+1}/{max_steps}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Worst-Group Accuracy\n",
    "Compute min accuracy over the four subgroups (domain×label).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Cell 8 (CPU only): Evaluation Metric**\n",
    "import torch\n",
    "\n",
    "def worst_group_acc(model, domains):\n",
    "    allP, allL, allD = [], [], []\n",
    "    for d in domains:\n",
    "        loader = make_loader(d, \"test\", bs=64, shuffle=False)\n",
    "        for imgs, labs, dom in loader:\n",
    "            with torch.no_grad():\n",
    "                out = torch.sigmoid(model(imgs)).round()  # CPU\n",
    "            allP.append(out)\n",
    "            allL.append(labs)\n",
    "            allD.append(dom)\n",
    "    P = torch.cat(allP)\n",
    "    L = torch.cat(allL)\n",
    "    D = torch.cat(allD)\n",
    "    accs = []\n",
    "    for d_val in torch.unique(D):\n",
    "        for c in [0,1]:\n",
    "            mask = (D==d_val)&(L==c)\n",
    "            accs.append((P[mask]==L[mask]).float().mean().item())\n",
    "    return min(accs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Run Experiments & Plot\n",
    "Compare single-domain (A) vs. multi-domain (A+B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Cell 9: Execute & Compare**\n",
    "# --------------------------------------------------------------\n",
    "# Single-domain\n",
    "modelA = train_erm([\"A\"])\n",
    "wgA = worst_group_acc(modelA, [\"A\"])\n",
    "# Multi-domain\n",
    "modelAB = train_erm([\"A\",\"B\"])\n",
    "wgAB = worst_group_acc(modelAB, [\"A\",\"B\"])\n",
    "\n",
    "print(f\"Single-domain worst-group acc: {wgA:.3f}\")\n",
    "print(f\"Multi-domain worst-group acc:   {wgAB:.3f}\")\n",
    "print(f\"Δ (multi – single):             {wgAB - wgA:+.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Cell 10: Visualization**\n",
    "# --------------------------------------------------------------\n",
    "plt.bar([\"Single\",\"Multi\"], [wgA, wgAB], color=[\"C0\",\"C1\"])\n",
    "plt.ylabel(\"Worst-Group Accuracy\")\n",
    "plt.title(\"When More Is Less: Single vs. Multi Domain\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusion:**  \n",
    "If Δ < 0, you’ve demonstrated that adding Domain B hurts the worst-group accuracy—i.e., “more is less,” reproducing the core finding from Compton et al.\n",
    "\n",
    "Feel free to tweak:\n",
    "- `max_steps`, learning rate, batch sizes  \n",
    "- Pseudo-label threshold or pathology choice  \n",
    "- Augmentation strength for Domain B  \n",
    "\n",
    "to see how robust the phenomenon is in your own data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Cell X: Metrics & Evaluation Utilities**\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate_model(model, domains, split=\"test\", batch_size=64):\n",
    "    \"\"\"\n",
    "    Runs the model on all domains for the given split and\n",
    "    returns a DataFrame with columns:\n",
    "      - domain (int)\n",
    "      - y_true  (0/1)\n",
    "      - y_pred  (0/1)\n",
    "      - y_score (float, sigmoid output)\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for d in domains:\n",
    "            loader = make_loader(d, split, bs=batch_size, shuffle=False)\n",
    "            for imgs, labels, dom in loader:\n",
    "                imgs = imgs  # CPU / CUDA as configured\n",
    "                logits = model(imgs).squeeze()\n",
    "                probs  = torch.sigmoid(logits).cpu().numpy()\n",
    "                preds  = (probs >= 0.5).astype(int)\n",
    "                \n",
    "                # record each example\n",
    "                for i in range(len(probs)):\n",
    "                    records.append({\n",
    "                        \"domain\": int(dom[i].item()),\n",
    "                        \"y_true\": int(labels[i].item()),\n",
    "                        \"y_pred\": int(preds[i]),\n",
    "                        \"y_score\": float(probs[i]),\n",
    "                    })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def compute_group_accuracies(df):\n",
    "    \"\"\"\n",
    "    Given the DataFrame from evaluate_model, returns:\n",
    "      - group_acc: dict[(domain, class) -> accuracy]\n",
    "      - worst_group_acc: float\n",
    "      - overall_acc: float\n",
    "      - aurocs: dict[domain or 'overall' -> AUROC]\n",
    "    \"\"\"\n",
    "    group_acc = {}\n",
    "    for (d, c), sub in df.groupby([\"domain\", \"y_true\"]):\n",
    "        if len(sub) == 0:\n",
    "            acc = np.nan\n",
    "        else:\n",
    "            acc = (sub.y_pred == sub.y_true).mean()\n",
    "        group_acc[(d, c)] = acc\n",
    "\n",
    "    # worst‐group is the minimum over valid groups\n",
    "    worst_group_acc = min(v for v in group_acc.values() if not np.isnan(v))\n",
    "\n",
    "    # overall accuracy\n",
    "    overall_acc = (df.y_pred == df.y_true).mean()\n",
    "\n",
    "    # AUROC per domain and overall\n",
    "    aurocs = {}\n",
    "    # overall\n",
    "    try:\n",
    "        aurocs[\"overall\"] = roc_auc_score(df.y_true, df.y_score)\n",
    "    except ValueError:\n",
    "        aurocs[\"overall\"] = np.nan\n",
    "\n",
    "    # per-domain\n",
    "    for d, sub in df.groupby(\"domain\"):\n",
    "        try:\n",
    "            aurocs[d] = roc_auc_score(sub.y_true, sub.y_score)\n",
    "        except ValueError:\n",
    "            aurocs[d] = np.nan\n",
    "\n",
    "    return group_acc, worst_group_acc, overall_acc, aurocs\n",
    "\n",
    "def eval_and_report(model, domains, split=\"test\"):\n",
    "    \"\"\"\n",
    "    Convenience wrapper: evaluate + compute metrics + print summary.\n",
    "    Returns a dict with all metrics and the raw DataFrame.\n",
    "    \"\"\"\n",
    "    df = evaluate_model(model, domains, split=split)\n",
    "    group_acc, worst, overall, aurocs = compute_group_accuracies(df)\n",
    "\n",
    "    print(f\"--- Evaluation on split='{split}' domains={domains} ---\")\n",
    "    print(f\"Overall Accuracy : {overall:.3f}\")\n",
    "    print(f\"Worst-Group Acc  : {worst:.3f}\")\n",
    "    print(\"Group Accuracies :\")\n",
    "    for (d,c), acc in sorted(group_acc.items()):\n",
    "        print(f\"  Domain {d}, Class {c}: {acc:.3f}\")\n",
    "    print(\"AUROC Scores     :\")\n",
    "    for k,v in aurocs.items():\n",
    "        print(f\"  {k!s:>7}: {v:.3f}\")\n",
    "    \n",
    "    # return for further use\n",
    "    return {\n",
    "      \"df\": df,\n",
    "      \"group_acc\": group_acc,\n",
    "      \"worst_group_acc\": worst,\n",
    "      \"overall_acc\": overall,\n",
    "      \"aurocs\": aurocs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsA   = eval_and_report(modelA, [\"A\"])\n",
    "metricsAB  = eval_and_report(modelAB, [\"A\",\"B\"])\n",
    "\n",
    "# To export sub‐group results to CSV:\n",
    "metricsAB[\"df\"].to_csv(\"eval_AB.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs598env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
